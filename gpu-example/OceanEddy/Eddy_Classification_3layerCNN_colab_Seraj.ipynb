{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Eddy_Classification_3layerCNN_colab_Seraj.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##This notebook can be used to classify the images with eddy from non-eddy using google colab platform."
      ],
      "metadata": {
        "id": "W4kko3Sko3r3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mount directories from google drive"
      ],
      "metadata": {
        "id": "XUlLoZHsosjD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUv9EvlV2dOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b6143a6-8b80-497a-d857-a2e23e06cbb2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import libraries"
      ],
      "metadata": {
        "id": "Yc0tPcvUor-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###libraries"
      ],
      "metadata": {
        "id": "lJyzYPY3q8QG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ljMDYt7IIqsm"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import keras\n",
        "import os"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fap6urzIqsr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4d166e-8477-49c9-86e7-be97c8d83f0c"
      },
      "source": [
        "data_path = ('/content/drive/MyDrive/ESIP-Ocean-Eddy-Detection/demo_png')\n",
        "data_path = ('/content/drive/MyDrive/path_to_dir')\n",
        "img_path= data_path\n",
        "os.chdir(img_path)\n",
        "print(os.path.abspath(os.getcwd()))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1KS2muRwn4VXnctrNWa5dx0K8BIIRSELD/ESIP-Ocean-Eddy-Detection/demo_png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###libraries"
      ],
      "metadata": {
        "id": "YcIGCv9bq7T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "# import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "TQOQapEwqrRL"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(2)\n",
        "#https://machinelearningmastery.com/reproducible-results-neural-networks-keras/"
      ],
      "metadata": {
        "id": "sZYemBBMGgwJ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65hJ37VTIqss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a78b876-e489-4f46-e360-a2508e548f15"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(8, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "# plot_model(model, to_file='model_plot11.png', show_shapes=True, show_layer_names=True)\n",
        "model.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 254, 254, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 127, 127, 32)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 62, 62, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 60, 60, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 30, 30, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 28800)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 8)                 230408    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 267,697\n",
            "Trainable params: 267,697\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu9wo85vIqss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a1718c6-c490-48b3-9210-a30cfb6523e0"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# # this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=False) ## cannot do flip\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "\n",
        "# this is a generator that will read pictures found in\n",
        "# subfolers of 'data/train', and indefinitely generate\n",
        "# batches of augmented image data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # '/content/drive/MyDrive/ESIP-Ocean-Eddy-Detection/demo_png/train',  # this is the target directory\n",
        "        '/content/drive/MyDrive/path_to_dir/train' # this is the target directory\n",
        "        target_size=(256, 256),  # all images will be resized to 150x150\n",
        "        color_mode = 'grayscale',\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
        "\n",
        "# this is a similar generator, for validation data\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        # '/content/drive/MyDrive/ESIP-Ocean-Eddy-Detection/demo_png/validation',\n",
        "        '/content/drive/MyDrive/path_to_dir/validation',\n",
        "        target_size=(256, 256),\n",
        "        color_mode = 'grayscale',\n",
        "        batch_size=1,\n",
        "        class_mode='binary')\n",
        "\n",
        "# this is a similar generator, for validation data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        # '/content/drive/MyDrive/ESIP-Ocean-Eddy-Detection/demo_png/test',\n",
        "        '/content/drive/MyDrive/path_to_dir/test',\n",
        "        target_size=(256, 256),\n",
        "        color_mode = 'grayscale',\n",
        "        batch_size=1,\n",
        "        class_mode=None,\n",
        "        shuffle=False)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 42 images belonging to 2 classes.\n",
            "Found 22 images belonging to 2 classes.\n",
            "Found 15 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zti3cZ_HIqst"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwSnTCu-Iqsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e7c2e2-7cc8-4ce0-df03-3d81cf8a57f9"
      },
      "source": [
        "h = model.fit(\n",
        "        train_generator,\n",
        "        # steps_per_epoch=200 // batch_size,\n",
        "        epochs=10,\n",
        "        validation_data=validation_generator,\n",
        "        # validation_steps=80 // batch_size\n",
        "        )"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 5s 1s/step - loss: 0.3944 - accuracy: 0.5952 - val_loss: 0.0793 - val_accuracy: 0.9091\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0452 - accuracy: 0.9524 - val_loss: 0.0816 - val_accuracy: 0.9091\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0408 - accuracy: 0.9524 - val_loss: 0.0667 - val_accuracy: 0.9091\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0335 - accuracy: 0.9762 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Average accuracy: \",sum(h.history['accuracy'])/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnueDPLKCLvH",
        "outputId": "1ccfd2db-1427-4080-ed6f-40e0b9a59467"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy:  0.9476190447807312\n"
          ]
        }
      ]
    }
  ]
}