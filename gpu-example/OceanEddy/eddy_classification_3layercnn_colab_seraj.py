# -*- coding: utf-8 -*-
"""Eddy_Classification_3layerCNN_colab_Seraj.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G-GTY1GutQzyKqgtyIZjlHCtFEBEm383

##This notebook can be used to classify the images with eddy from non-eddy using google colab platform.

###Mount directories from google drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""###Import libraries

###libraries
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import cv2
import keras
import os

data_path = ('/content/drive/MyDrive/path_to_dir')
img_path= data_path
os.chdir(img_path)
print(os.path.abspath(os.getcwd()))

"""###libraries"""

# import tensorflow as tf
from tensorflow.keras import datasets, layers, models
# import matplotlib.pyplot as plt
from tensorflow.keras.utils import plot_model

from numpy.random import seed
seed(1)
import tensorflow
tensorflow.random.set_seed(2)

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(32, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(8, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
# plot_model(model, to_file='model_plot11.png', show_shapes=True, show_layer_names=True)
model.summary()

batch_size = 16

from keras.preprocessing.image import ImageDataGenerator

# # this is the augmentation configuration we will use for training
train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=False) ## cannot do flip

# this is the augmentation configuration we will use for testing:
# only rescaling
test_datagen = ImageDataGenerator(
        rescale=1./255)

# this is a generator that will read pictures found in
# subfolers of 'data/train', and indefinitely generate
# batches of augmented image data
train_generator = train_datagen.flow_from_directory(
        '/content/drive/MyDrive/path_to_dir/train' # this is the target directory
        target_size=(256, 256),  # all images will be resized to 150x150
        color_mode = 'grayscale',
        batch_size=batch_size,
        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels

# this is a similar generator, for validation data
validation_generator = test_datagen.flow_from_directory(
        '/content/drive/MyDrive/path_to_dir/validation',
        target_size=(256, 256),
        color_mode = 'grayscale',
        batch_size=1,
        class_mode='binary')

# this is a similar generator, for validation data
test_generator = test_datagen.flow_from_directory(
        '/content/drive/MyDrive/path_to_dir/test',
        target_size=(256, 256),
        color_mode = 'grayscale',
        batch_size=1,
        class_mode=None,
        shuffle=False)

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

h = model.fit(
        train_generator,
        # steps_per_epoch=200 // batch_size,
        epochs=10,
        validation_data=validation_generator,
        # validation_steps=80 // batch_size
        )

print("Average accuracy: ",sum(h.history['accuracy'])/10)
